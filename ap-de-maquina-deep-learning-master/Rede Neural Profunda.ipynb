{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota√ß√£o matem√°tica utilizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos uma nota√ß√£o matem√°tica similar a da pr√°tica de regress√£o log√≠stica, com algumas modifica√ß√µes. Elementos modificados est√£o em azul, novos est√£o em verdes e, n√£o modificados, em preto.\n",
    "\n",
    "- $m$: quantidade de instancias\n",
    "- $f$: quantidade de atributos\n",
    "- $n^{[l]}$: quantidade de unidades da camada $l$ \n",
    "- $X$: Matriz de inst√¢ncias representadas pelo seus atributos a ordem da matriz √© $m \\times f$\n",
    "- $\\pmb{y}$: Vetor de tamanho $m$ representando a classe real de cada inst√¢ncia\n",
    "- $\\pmb{\\hat{y}}$: Vetor de predi√ß√µes que, para cada instancia, possui o valor predito para ela. Caso seja uma classifica√ß√£o bin√°ria, este valor ser√° 0 ou 1\n",
    "\n",
    "- $Z^{[l]}$: Matriz, para cada instancia, o valor $z^{[l]}_{i,j}$ representando o resultado da fun√ß√£o `z` para instancia $i$ e unidade $j$. Essa matriz √© de ordem $m \\times n^{[l]}$\n",
    "\n",
    "- $A^{[l]}$ Matriz de ativa√ß√µes da camada $l$ em que, $a^{[l]}_{i,j}$ √© um elemento dessa matriz que representa a ativa√ß√£o da instancia $i$ na camada $l$ na unidade $j$. Dessa forma essa √© uma matriz de ordem $m \\times n^{[l]}$.\n",
    "\n",
    "- $W^{[l]}$ Matriz de pesos da camada $l$ em que cada elemento $w^{[l]}_{i,j}$ representa pondera√ß√£o que a unidade $i$ da camada $l$ faz na unidade $j$ da matriz de ativa√ß√£o $A^{[l-1]}$. Caso seja primeira camada, a pondera√ß√£o feita no atributo $j$ da matriz $X$. Dessa forma, essa matriz √© de ordem $n^{[l]} \\times n^{[l-1]}$ exceto na primeira camada que √© de ordem $n^{[l]} \\times f$\n",
    "\n",
    "- $Z^{d[l]}$: Derivada $\\frac{\\partial J}{\\partial z^{[l]}_{i,j}}$. Possui a mesma ordem que $Z$\n",
    "\n",
    "- $W^{d[l]}$: Derivada $\\frac{\\partial J}{\\partial w^{[l]}_{i,j}}$. Possui a mesma ordem que $W$\n",
    "\n",
    "Como em nossa implementa√ß√£o temos tamb√©m representado os elementos por unidade, tamb√©m usaremos a representa√ß√£o por unidade $j$ em uma determinada camada $l$, apresetnada a seguir. Note que s√£o os mesmos elementos da pr√°tica de regress√£o, por√©m, nesta pr√°tica, temos que definir a qual unidade $j$ e camada $l$ estamos nos referindo.\n",
    "\n",
    "- $\\pmb{z}^{[l]}_j$: $j$-√©sima coluna da matriz $Z^{[l]}$ representado o resultado da fun√ß√£o z, para cada instancia $m$ da unidade $j$ e camada $l$. Assim, este vetor possui o tamanho $m$.\n",
    "- $\\pmb{a}^{[l]}_j$: $j$-√©sima coluna da matriz $A^{[l]}$ representando o vetor de ativa√ß√µes da unidade $j$ de tamanho $m$ calculada por meio do vetor $z^[l]_j$\n",
    "- $\\pmb{w}^{[l]}_{j}$: j-√©sima **linha** da matriz $W^{[l]}$ que representa vetor de pesos de uma unidade (neur√¥nio) $j$ para ponderar os pesos da camada anterior ou, caso seja a primeira camada, pondera os atributos. Assim, esse vetor possui o tamanho $f$ (primeira camada) e tamanho  $n^{[l-1]}$ (demais camadas).\n",
    "\n",
    "\n",
    "- $b^{[l]}_j$: Valor de vi√©s da unidade $j$ e camada $l$ (do ingl√™s, bias term)\n",
    "<!--- <span class=\"blue\" style=\"color:blue\">$w_j$: $j$-√©simo valor do vetor $\\pmb{w}$ que pondera $j$-√©sima coluna da matriz $A^{[l]}$. Essa coluna representa a $j$-√©sima  unidade da camada anterior ou, quando for a primeira camada, o $j$-√©simo atributo da matriz $X$</span>.-->\n",
    "\n",
    "Al√©m das representa√ß√µes das derivadas por unidade $j$  em uma determinada camada $l$:\n",
    "\n",
    "- $\\pmb{z}^{d[l]}_j$: Vetor de derivada $\\frac{\\partial J}{\\partial z_j}$ para cada inst√¢ncia $i$ do modelo de uma determinada unidade $j$ e camada $l$ em uma determinada camada $l$. Possui o mesmo tamanho que  $\\pmb{z}$\n",
    "- $\\pmb{w}^{d[l]}_j$ Vetor de derivada $\\frac{\\partial J}{\\partial w_j}$ para cada unidade $j$ do modelo, possui o mesmo tamanho de $\\pmb{w}^{[l]}_{j}$\n",
    "- $b^{d[l]}_j$: Derivada $\\frac{\\partial J}{\\partial b^{[l]}_j}$ \n",
    "\n",
    "Perceba que esses vetores representam a $j$-√©sima coluna de suas respectivas matrizes, para cada unidade $j$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementa√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, apresentaremos as modifica√ß√µes que devem ser feitas por classe. Primeiramente, execute as importan√ß√µes que usaremos na pr√°tica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from rede_neural_profunda import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe FuncaoAtivacao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - Fun√ß√µes de ativa√ß√µes novas e altera√ß√£o na fun√ß√£o sigmoid**: Voc√™ agora poder√° ver 4 objetos da classe `FuncaoAtivacao` instanciados: sigmoid, relu, leaky_relu e tanh. Voc√™ dever√° modificar alterar as suas fun√ß√µes lambda para retornar o resultado correto, dependendo da fun√ß√£o de ativa√ß√£o.\n",
    "\n",
    "O valor do vetor de derivadas $\\pmb{z^{d[l]}_j}$ √© diferente caso estejamos na √∫ltima camada. Por isso, na classe `FuncaoAtivacao` agora temos um atributo (opcional) `dz_ultima_camada` que √© a fun√ß√£o da derivada quando  calculamos o vetor $\\pmb{z^{d[l]}_j}$ na √∫ltima camada com uma determinada fun√ß√£o de ativa√ß√£o. A fun√ß√£o de ativa√ß√£o `sigmoid` ser√° a √∫nica que usaremos como √∫ltima camada, assim, altere o objeto `sigmoid`com a fun√ß√£o  `dz_ultima_camada` correspondente. \n",
    "\n",
    "O atributo `dz_ultima_camada` do objeto sigmoid ter√° a fun√ß√£o que usamos como `dz_funcao`  na pr√°tica passada. Agora, o parametro `dz_funcao` ser√° diferente: temos que usar o par√¢metro `arr_dz_w_prox` representando a $j$-√©sima coluna do produto $Z^{d[l+1]} \\times W^{[l+1]}$. Crie tamb√©m as fun√ß√µes de ativa√ß√£o relu, leaky_relu e tangente hiperb√≥lica (vari√°veis `relu`, `leaky_relu` e `tanh`, respectivamente) usando apenas os par√¢metros do construtor `funcao` e `dz_funcao`. Lembrando que n√£o usaremos as fun√ß√µes de ativa√ß√£o `relu`, `leaky_relu` e `tanh` como √∫ltima camada (camada de sa√≠da). Para implementar essas express√µes lambda, voc√™ poder√° usar vetoriza√ß√£o. Lembre-se do seguinte c√≥digo da pr√°tica de regress√£o log√≠stica: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "meu_querido_vetor = np.array([3,2,8,9,2])\n",
    "#a linha abaixo retorna true ou false, dependendo do valor\n",
    "print(meu_querido_vetor>4)\n",
    "#Se multiplicamos um n√∫mero por um vetor numpy de true e false \n",
    "#. √© o mesmo de multiplicarmos o n√∫mero por 1 ou 0, respectivamente\n",
    "print(3*(meu_querido_vetor>4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestFuncaoAtivacao.test_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestFuncaoAtivacao.test_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestFuncaoAtivacao.test_leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestFuncaoAtivacao.test_tanh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Altera√ß√£o da classe `RegressaoLogistica` para `Unidade`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classe Unidade:** A classe RegressaoLogistica da pr√°tica anterior foi renomeada para Unidade.  Essa classe j√° est√° pronta, agora, ela representar√° uma unidade (neur√¥nio). Alguns atributos  foram removidos (pois agora n√£o criamos o modelo apenas com uma unidade) e um √∫nico atributo foi modificado: tinhamos antes o `mat_x`, representando a matriz $X$, ao inv√©s dele, temos que utilizar a matriz $A^{[l-1]}$, ou seja, a matriz de ativa√ß√µes da camada anterior. Essa matriz, representada pelo atributo `mat_a_ant`, √© usada no lugar de `mat_x` para calcular o `forward_propagation` e o `backward_propagation`. Reveja a implementa√ß√£o e relembre os atributos dela:\n",
    "\n",
    "- `b`: Valor $b$ de vi√©s da regress√£o log√≠stica \n",
    "- `func_ativacao`: fun√ß√£o de ativa√ß√£o a ser usada. Esse atributo √© uma fun√ß√£o Python\n",
    "- `dz_func`: fun√ß√£o derivada a ser usada de acordo com a fun√ß√£o de ativa√ß√£o\n",
    "- `arr_w`: vetor de pesos $\\pmb{w^{[l]}_{j}}$\n",
    "- `arr_z`: vetor de resultados $\\pmb{z^{[l]}_{j}}$ \n",
    "- `arr_a`: vetor de ativa√ß√µes $\\pmb{a^{[l]}_{j}}$\n",
    "- `mat_a_ant`: Matriz de ativa√ß√µes da camada anterior $A^{[l-1]}$ (ou matriz $X$, caso esta seja a primeira camada)\n",
    "- `gradiente`: Instancia da classe `Gradiente` que possui os atributos `arr_dz`, `arr_dw` e `db` representando, respectivamente, $\\pmb{z^{d[l]}_j}$, $\\pmb{w^{d[l]}_j}$ e $b^{d[l]}_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementa√ß√£o da classe Camada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe camada possui os seguintes atributos:\n",
    "\n",
    "- `arr_unidades`: Vetor de unidades (neur√¥nios) desta camada. Representada por inst√¢ncias da classe `Unidade`. S√£o inicializados por meio dos parametros do construtor que definem a quantidade de unidades, fun√ß√£o de ativa√ß√£o e derivada (`qtd_unidades`, `func_ativacao` e `func_dz` respectivamente).\n",
    "- `ant_camada`: Inst√¢ncia da classe `Camada` referente √† camada anterior. Caso seja a primeira camada escondida, ent√£o `ant_camada == None`\n",
    "- `prox_camada`: Inst√¢ncia da classe `Camada` referente √† proxima camada. Caso seja a √∫ltima camada (camada de sa√≠da), ent√£o `prox_camada == None`\n",
    "- `qtd_un_camada_ant`: Quantidade de unidades da camada anterior, armazena o valor $n^{[l-1]}$ exceto na primeira camada que recebe o valor $f$ \n",
    "- `mat_w`: atributo calculado (`property`) representando a matriz de pesos $W^{[l]}$ desta camada\n",
    "- `mat_dz`: atributo calculado (`property`) representando a derivada $Z^{d[l]}$. \n",
    "- `mat_dz_w`: Atributo calculado que efetua o produto $Z^{d[l]} \\times W^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - construtor da classe `Camada`**: Inicialize o vetor de `arr_unidades` com a quantidade de unidades correspondente (use os par√¢metros do construtor da classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestCamada.test_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - m√©todo `forward_propagation` da classe `Camada`**: Nesse m√©todo, voc√™ dever√° criar a matriz de ativa√ß√£o $A^{[l]}$ da camada atual $l$ (representada por `mat_a`) por meio da matriz de ativa√ß√µes anterior $A^{[l-1]}$ (representada por `mat_a_ant`). Para isso, voc√™ dever√° chamar o m√©todo `forward_propagation` de cada unidade (classe Unidade), implementado por voc√™s na pr√°tica de Regress√£o Log√≠stica, que cria o vetor $\\pmb{a^{[l]}_j}$, representado por `arr_a` de cada unidade. Para criar a matriz `mat_a`, observe sempre a sua dimens√£o. Dica: veja abaixo uma forma de preencher valores em linhas/colunas de uma matriz numpy por meio de vetores. Voc√™ dever√° usar [np.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html) para inicializar a matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#considere a matriz mat_h e o vetor arr_linha e arr_coluna:\n",
    "mat_h = np.zeros((10,5))\n",
    "arr_linha = np.random.rand(5)\n",
    "arr_coluna = np.random.rand(10)\n",
    "print(mat_h)\n",
    "print(arr_linha)\n",
    "print(arr_coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para preenchermos a linha 3 com o vetor arr_linha:\n",
    "mat_h[3,:] = arr_linha\n",
    "mat_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#para preenchermos a coluna 2 com o vetor arr_coluna: \n",
    "mat_h[:,2] = arr_coluna\n",
    "mat_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestCamada.test_forward_propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 - propriedades da classe `Camada`**: Voc√™ dever√° implementar as propriedades `mat_w` e `mat_dz` para criar as matrizes $W^{[l]}$ e $Z^{d[l]}$. Logo ap√≥s, voc·∫Ω dever√° implementar a propriedade `mat_dz_w` que calcula $Z^{d[l]} \\times W^{[l]}$. Fique atento nas dimens√µes das matrizes para usar o preenchimento de matrizes corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestCamada.test_mat_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestCamada.test_mat_dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestCamada.test_mat_dz_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - m√©todo backward_propagation da classe `Camada`:** Por meio da matriz `mat_dz_dw` da camada seguinte, ou seja, o resultado de $Z^{d[l+1]} \\times W^{[l+1]}$ e do vetor de classes $\\pmb{y}$, execute o backward propagation de todas as unidades. Para obter o `mat_dz_dw` da camada seguinte n√£o esque√ßa que as camadas possuem o atributo `prox_camada`. Caso essa seja a √∫ltima camada, ent√£o `mat_dz_dw == None`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestCamada.test_backward_propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementa√ß√£o da classe `RedeNeural`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe `RedeNeural` possui os seguintes atributos: \n",
    "\n",
    "- `arr_camadas`: Vetor que armazena a lista de instancias da classe `Camada` dessa Rede Neural. Esses objetos s√£o instanciados por meio do m√©todo `config_rede`\n",
    "- `arr_qtd_un_por_camada`: Vetor de inteiros que, o valor na posi√ß√£o `i` do vetor corresponde a quantidade de unidades na i-√©sima camada.\n",
    "- `arr_func_a_por_camada`: Fun√ß√£o de ativa√ß√£o por camada. Esse vetor armazena objetos da classe `FuncaoAtivacao` em que, cada posi√ß√£o `i` do vetor, corresponde a fun√ß√£o de ativa√ß√£o da i-√©sima camada\n",
    "- `num_iteracoes`: N√∫mero de itera√ß√µes (√©pocas) que a rede neural ir√° rodar\n",
    "- `arr_y`: Representa o vetor $\\pmb{y}$. Esses objetos s√£o instanciados por meio do m√©todo `config_rede`\n",
    "- `mat_x`: Representa a matriz de atributos por instancias $X$. Esses objetos s√£o instanciados por meio do m√©todo `config_rede`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - m√©todo `config_rede`**: instancia  armazena em arr_camada todas as camadas por meio da\n",
    "        quantidade de unidades por camada `arr_qtd_un_por_camada` e fun√ß√µes de ativa√ß√£o `arr_func_a_por_camada`. Para cada camada, voc√™ dever√° referenciar a camada anterior e a pr√≥xima por meio os atributos `ant_camada` e `prox_camada`, respectivamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C√≥digo Python √∫til para atividades 7 e 8:** Muitas vezes, precisamos percorrer vetores a partir de uma determinada posi√ß√£o ou de tr√°s para frente. Veja como isso pode ser feito usando a fun√ß√£o [range](https://docs.python.org/3/library/functions.html#func-range) e a fun√ß√£o [enumerate](https://docs.python.org/3/library/functions.html#enumerate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_v = [4,2,4,5,3,1]\n",
    "tam_vet = len(arr_v)\n",
    "#percorrer elementos de tras para frente\n",
    "print(\"Tras para frente: \")\n",
    "for i in range(tam_vet-1,-1,-1):\n",
    "    print(f\"Pos arr_v[{i}]: {arr_v[i]}\")\n",
    "print(\"---\")\n",
    "print(\"A partir do 3o: \")\n",
    "#percorrer elementos a partir do indice 3\n",
    "for i in range(3,tam_vet):\n",
    "    print(f\"Pos arr_v[{i}]: {arr_v[i]}\")\n",
    "    \n",
    "#Com o enumerate, tamb√©m conseguimos percorrer a partir de uma posi√ß√£o\n",
    "#..Lembre que arr_v[3:] retorna o vetor a partir da terceira posi√ß√£o \n",
    "print(\"mesma efeito, com enumerate:\")\n",
    "for i,valor in enumerate(arr_v[3:],3):\n",
    "    print(f\"Pos arr_v[{i}]: {valor}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2021-04-14 09:47:38,662] Finished trial#0 with value: 2.0 with parameters: {'y': 2}. Best is trial#0 with value: 2.0.\n",
      "[I 2021-04-14 09:47:38,859] Finished trial#1 with value: 4.0 with parameters: {'y': 4}. Best is trial#0 with value: 2.0.\n",
      "[I 2021-04-14 09:47:39,036] Finished trial#2 with value: 6.0 with parameters: {'y': 6}. Best is trial#0 with value: 2.0.\n",
      "[I 2021-04-14 09:47:39,215] Finished trial#3 with value: 5.0 with parameters: {'y': 5}. Best is trial#0 with value: 2.0.\n",
      "[I 2021-04-14 09:47:39,388] Finished trial#4 with value: 3.0 with parameters: {'y': 3}. Best is trial#0 with value: 2.0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All grids have been evaluated. If you want to avoid this error, please make sure that unnecessary trials do not run during optimization by properly setting `n_trials` in `study.optimize`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9519ab63f05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msearch_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m                 self._optimize_sequential(\n\u001b[0;32m--> 339\u001b[0;31m                     \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 )\n\u001b[1;32m    341\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[1;32m    680\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[0;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;31m# type: (...) -> None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrial_id\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0mtrial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_new_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0mtrial_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/trial/_trial.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, study, trial_id)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_relative_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_relative_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/trial/_trial.py\u001b[0m in \u001b[0;36m_init_relative_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_search_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_relative_search_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         self.relative_params = self.study.sampler.sample_relative(\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelative_search_space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/optuna/samplers/grid.py\u001b[0m in \u001b[0;36msample_relative\u001b[0;34m(self, study, trial, search_space)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munvisited_grids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0;34m\"All grids have been evaluated. If you want to avoid this error, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;34m\"please make sure that unnecessary trials do not run during \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;34m\"optimization by properly setting `n_trials` in `study.optimize`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: All grids have been evaluated. If you want to avoid this error, please make sure that unnecessary trials do not run during optimization by properly setting `n_trials` in `study.optimize`."
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    y = trial.suggest_int(\"y\", -99, 99)\n",
    "    return y\n",
    "\n",
    "\n",
    "search_space = {\"y\": [2,3,4,5,6]}\n",
    "study = optuna.create_study(sampler=optuna.samplers.GridSampler(search_space))\n",
    "study.optimize(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestRedeNeural.test_config_rede"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7 - m√©todo `forward_propagation`**: Execute, para todas as camadas, o m√©todo forward_propagation. Note que, para primeira camada,\n",
    "    a entrada ser√° a matriz $X$, representada por `mat_x` e, as demais, seriam a matriz $A^{[l-1]}$, ou seja, a matriz de ativa√ß√µes da camada anterior. Lembre-se que cada camada possui sua matriz de ativa√ß√µes representada\n",
    "    pelo atributo `mat_a` e temos o vetor de camadas para podemos acessar as camadas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestRedeNeural.test_forward_propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - m√©todo `backward_propagation`**: Execute, para todas as camadas, o m√©todo backward_propagation. Fique atento na ordem de execu√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestRedeNeural.test_backward_propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - m√©todo `fit`**: SImilar ao m√©todo `fit` que implementamos na pr√°tica de Regress√£o Log√≠stica, realiza self.num_iteracoes itera√ß√µes (√©pocas) da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestRedeNeural.test_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10 - m√©todo `loss_function`**: Para calcular o `loss_function`, voc√™ dever√° obter o vetor de ativa√ß√µes $\\pmb{a}$ (representado por `arr_a` em cada unidade) apropriado. Fique atento em qual camada/unidade voc√™ dever√° obter o arr_a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 11 - m√©todo `predict`**: similar ao da regress√£o logistica, para uma determinada matriz $X$ representando todos os atributos a serem preditos, calcula a predi√ß√£o $\\pmb{\\hat{y}}$ para cada inst√¢ncia $\\in X$ por meio do m√©todo `forward_propagation` de um modelo j√° criado. Esse c√≥digo ser√° muito similar ao que fizemos na pr√°tica de regress√£o logistica, por√©m, dever√° ficar atento a qual camada/unidade voc√™ dever√° obter o vetor de ativa√ß√µes arr_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rede_neural_profunda_test TestRedeNeural.test_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo - Rede Neural Funcionando*  ü§© "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Assim espera-se ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#usaremos o mesmo dataset da pr√°tica de regrss√£o logistica:\n",
    "mat_x, arr_y = sklearn.datasets.make_moons(400, noise=0.05)\n",
    "plt.scatter(mat_x[:,0], mat_x[:,1], s=40, c=arr_y, cmap=plt.cm.Spectral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie uma rede neural de duas camadas a primeira com 4 unidades escondidas e, a segunda, com 1 unidade (essa seria a camada de sa√≠da). A fun√ß√£o de ativa√ß√£o da primeira camada ser√° uma Tangente Hiperb√≥lica (`tanh`) e, da segunda, uma `sigmoid`. Rode por 3.000 √©pocas. Ao trainar, coloque como learning rate=1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = None\n",
    "dnn.fit(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary(dnn,mat_x,arr_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa testes aumentando o n√∫mero de unidades, a fun√ß√£o de ativa√ß√£o e/ou aumentando a profundidade da rede neural. Descreva abaixo o que foi observado. Perceba que, nesta pr√°tica, fazer uma rede neural profunda geralmente n√£o ir√° melhorar o modelo. Um dos motivos √© que temos apenas 2 atributos. Uma rede neural profunda tende a melhorar o resultado quando temos diversos atributos, pois, em cada camada reduzimos a dimensionalidade do problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
