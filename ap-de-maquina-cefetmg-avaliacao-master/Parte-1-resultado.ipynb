{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prática: Criação da configuração experimental e avaliação dos resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta prática você irá terminar de desenvolver o código responsável por dividir o dataset em folds, métricas dos resultados e execução do método (Parte 1, no arquivo `resultados.py` e `metodo.py`), avaliação e configuração de parametros (Parte 2, no arquivo `avaliacao.py`) e, finalmente, irá aplicar isso em um cenário de classificação de segmentos de imagens de texturas diversas.\n",
    "\n",
    "[Veja os slides sobre as métricas de avaliação](https://docs.google.com/presentation/d/1u5x2b9BxmGXAWtfe9WanBIdqrt2k2ArKuEGY5Ks-okA/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antes de começar..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se da [aula de classes em Python](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/), mais especificamente:[Propriedades](https://www.youtube.com/watch?v=ocezOnXIzrc&list=PLwIaU1DGYV6skjkahOKtpgs9bPXlrVrIp&index=7) , [objetos que podem ser chamados](https://www.youtube.com/watch?v=EXmr7zttGWE&list=PLwIaU1DGYV6skjkahOKtpgs9bPXlrVrIp&index=9), [classes e herança](https://www.youtube.com/watch?v=zEP8baA_1lQ&list=PLwIaU1DGYV6skjkahOKtpgs9bPXlrVrIp&index=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dependencias: ** Para esta prática, você deverá instalar o optuna e o hiplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/69/60/87a06ef66b34cbe2f2eb0ab66f003664404a7f40c21403a69fad7e28a82b/optuna-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading optuna-3.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting hiplot\n",
      "  Downloading hiplot-0.1.33-py3-none-any.whl (863 kB)\n",
      "     ---------------------------------------- 0.0/863.2 kB ? eta -:--:--\n",
      "     ---- --------------------------------- 112.6/863.2 kB 3.3 MB/s eta 0:00:01\n",
      "     ------------ ------------------------- 276.5/863.2 kB 3.4 MB/s eta 0:00:01\n",
      "     ------------------ ------------------- 409.6/863.2 kB 3.7 MB/s eta 0:00:01\n",
      "     ---------------------- --------------- 512.0/863.2 kB 3.2 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 675.8/863.2 kB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 819.2/863.2 kB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 863.2/863.2 kB 2.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\development\\python3.11.3\\lib\\site-packages (1.25.2)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/a2/8b/46919127496036c8e990b2b236454a0d8655fd46e1df2fd35610a9cbc842/alembic-1.12.0-py3-none-any.whl.metadata\n",
      "  Downloading alembic-1.12.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting cmaes>=0.10.0 (from optuna)\n",
      "  Obtaining dependency information for cmaes>=0.10.0 from https://files.pythonhosted.org/packages/f7/46/7d9544d453346f6c0c405916c95fdb653491ea2e9976cabb810ba2fe8cd4/cmaes-0.10.0-py3-none-any.whl.metadata\n",
      "  Downloading cmaes-0.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\victor\\appdata\\roaming\\python\\python311\\site-packages (from optuna) (23.1)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Obtaining dependency information for sqlalchemy>=1.3.0 from https://files.pythonhosted.org/packages/10/81/230bec5713913a472003b71c8dd7e3572de44499e741df576fd6b39d82c8/SQLAlchemy-2.0.20-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.20-cp311-cp311-win_amd64.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: tqdm in c:\\development\\python3.11.3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Collecting PyYAML (from optuna)\n",
      "  Obtaining dependency information for PyYAML from https://files.pythonhosted.org/packages/b3/34/65bb4b2d7908044963ebf614fe0fdb080773fc7030d7e39c8d3eddcd4257/PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: ipython>=7.0.1 in c:\\development\\python3.11.3\\lib\\site-packages (from hiplot) (8.14.0)\n",
      "Collecting flask (from hiplot)\n",
      "  Obtaining dependency information for flask from https://files.pythonhosted.org/packages/fd/56/26f0be8adc2b4257df20c1c4260ddd0aa396cf8e75d90ab2f7ff99bc34f9/flask-2.3.3-py3-none-any.whl.metadata\n",
      "  Downloading flask-2.3.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting flask-compress (from hiplot)\n",
      "  Downloading Flask_Compress-1.13-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\development\\python3.11.3\\lib\\site-packages (from hiplot) (4.12.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 0.0/78.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 78.7/78.7 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=4 (from alembic>=1.5.0->optuna)\n",
      "  Obtaining dependency information for typing-extensions>=4 from https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: backcall in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (5.9.0)\n",
      "Requirement already satisfied: colorama in c:\\development\\python3.11.3\\lib\\site-packages (from ipython>=7.0.1->hiplot) (0.4.6)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-2.0.2-cp311-cp311-win_amd64.whl (192 kB)\n",
      "     ---------------------------------------- 0.0/192.5 kB ? eta -:--:--\n",
      "     -------------------------------------- 192.5/192.5 kB 5.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\development\\python3.11.3\\lib\\site-packages (from beautifulsoup4->hiplot) (2.4.1)\n",
      "Collecting Werkzeug>=2.3.7 (from flask->hiplot)\n",
      "  Obtaining dependency information for Werkzeug>=2.3.7 from https://files.pythonhosted.org/packages/9b/59/a7c32e3d8d0e546a206e0552a2c04444544f15c1da4a01df8938d20c6ffc/werkzeug-2.3.7-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask->hiplot)\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 0.0/133.1 kB ? eta -:--:--\n",
      "     ----------------------------------- -- 122.9/133.1 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 133.1/133.1 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting itsdangerous>=2.1.2 (from flask->hiplot)\n",
      "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\development\\python3.11.3\\lib\\site-packages (from flask->hiplot) (8.1.3)\n",
      "Collecting blinker>=1.6.2 (from flask->hiplot)\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting brotli (from flask-compress->hiplot)\n",
      "  Downloading Brotli-1.0.9-cp311-cp311-win_amd64.whl (333 kB)\n",
      "     ---------------------------------------- 0.0/333.1 kB ? eta -:--:--\n",
      "     ---------------------------- --------- 245.8/333.1 kB 7.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 333.1/333.1 kB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\development\\python3.11.3\\lib\\site-packages (from jedi>=0.16->ipython>=7.0.1->hiplot) (0.8.3)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask->hiplot)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/be/bb/08b85bc194034efbf572e70c3951549c8eca0ada25363afc154386b5390a/MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\development\\python3.11.3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.0.1->hiplot) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\development\\python3.11.3\\lib\\site-packages (from stack-data->ipython>=7.0.1->hiplot) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\development\\python3.11.3\\lib\\site-packages (from stack-data->ipython>=7.0.1->hiplot) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\development\\python3.11.3\\lib\\site-packages (from stack-data->ipython>=7.0.1->hiplot) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\development\\python3.11.3\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=7.0.1->hiplot) (1.12.0)\n",
      "Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
      "   ---------------------------------------- 0.0/404.2 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 256.0/404.2 kB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 404.2/404.2 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 226.0/226.0 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
      "Downloading SQLAlchemy-2.0.20-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.2/2.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.6/2.0 MB 8.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.1/2.0 MB 8.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.0 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.6/2.0 MB 7.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.9/2.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.2 MB/s eta 0:00:00\n",
      "Downloading flask-2.3.3-py3-none-any.whl (96 kB)\n",
      "   ---------------------------------------- 0.0/96.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 96.1/96.1 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "   ---------------------------------------- 0.0/144.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 144.7/144.7 kB 8.4 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 242.2/242.2 kB 14.5 MB/s eta 0:00:00\n",
      "Downloading MarkupSafe-2.1.3-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Installing collected packages: brotli, typing-extensions, PyYAML, MarkupSafe, itsdangerous, greenlet, colorlog, cmaes, blinker, Werkzeug, sqlalchemy, Mako, Jinja2, flask, alembic, optuna, flask-compress, hiplot\n",
      "Successfully installed Jinja2-3.1.2 Mako-1.2.4 MarkupSafe-2.1.3 PyYAML-6.0.1 Werkzeug-2.3.7 alembic-1.12.0 blinker-1.6.2 brotli-1.0.9 cmaes-0.10.0 colorlog-6.7.0 flask-2.3.3 flask-compress-1.13 greenlet-2.0.2 hiplot-0.1.33 itsdangerous-2.1.2 optuna-3.3.0 sqlalchemy-2.0.20 typing-extensions-4.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\development\\python3.11.3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna hiplot numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se do método *drop* e *sample* da prática passada ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Métricas de resultado, método de aprendizado e divisão por folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1**: Primeiramente, analise a classe `Resultado` que possui os seguintes atributos/propriedades: \n",
    "    \n",
    "   - **mat_confusão**: Retorna a matriz de confusão correpondente. Analise o código e entenda o que representa a linha e a coluna dessa matriz.\n",
    "    \n",
    "   - **precisao**:A partir da matriz de confusão, calcula a precisão por classe. Cada indice é o rótulo da classe. Caso o número de elementos previstos com uma determinada classe qualquer `c` seja zero, então `precisao[c] = 0`. Nesses casos, é [lançado um warning](https://docs.python.org/3.7/library/warnings.html) da classe `UndefinedMetricWarning` com uma mensagem que não havia instancias previstas para essa classe.\n",
    "   - **revocacao**: De forma similar à `precisao`, calcula a revocação por meio da matriz de confusão. Caso o número de elementos dessa classe seja igual a zero, então a revocação para esta class é zero e também deverá ser retornado um warning `UndefinedMetricWarning` com essa informação. \n",
    "   - **f1_por_classe**: Retorna, para cada classe, o seu valor F1. Caso a soma da precisão e revocação dessa classe seja zero, deverá ser retornado zero.\n",
    "\n",
    "Você deverá implementar as seguintes propriedades: \n",
    "\n",
    "   - **macro_f1**: Calcula a média do f1 por classe. O método [`np.average`](https://numpy.org/doc/stable/reference/generated/numpy.average.html) pode ajudar.\n",
    "   - **acuracia**: Calcula a acurácia  por meio da matriz de confusão.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logo após, execute os seguintes testes automatizados: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para validar o macro F1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m tests TestResultado.test_macro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar a acurácia: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m tests TestResultado.test_acuracia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - Classe ScikitLearnAprendizadoDeMaquina:** O arquivo `metodo.py` é o arquivo que possui os métodos de aprendizado de máquina. A classe `MetodoAprendizadoMaquina` é a classe abstrata para armazenar um método de aprendizado de máquina. Cada instancia, representa um método com seus determinados parametros. A classe `ScikitLearnaprendizadoDemaquina` é responsável por implementar métodos de aprendizado de máquina da API do [Scikit Learn](http://scikit-learn.org). Cada instancia desta classe armazena o respectivo método no atributo `ml_method`.  Por exemplo: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from metodo import ScikitLearnAprendizadoDeMaquina\n",
    "\n",
    "#o primeiro método é uma arvore de decisao\n",
    "clf_dtree_1 = DecisionTreeClassifier(random_state=1,min_samples_split=0.3)\n",
    "metodo_1 = ScikitLearnAprendizadoDeMaquina(clf_dtree_1)\n",
    "\n",
    "#veja que o segundo método também é uma arvore de decisão, porém, com paramtros diferentes\n",
    "clf_dtree_2 = DecisionTreeClassifier(random_state=1,min_samples_split=0.2)\n",
    "metodo_2 = ScikitLearnAprendizadoDeMaquina(clf_dtree_2)\n",
    "\n",
    "#terceiro método é uma RandomForest\n",
    "clf_rforest = RandomForestClassifier(min_samples_split=0.3,n_estimators=100,\n",
    "                                            max_features=0.7)\n",
    "metodo_3 = ScikitLearnAprendizadoDeMaquina(clf_rforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deverá implementar o método `eval` da classe `ScikitLearnAprendizadoDeMaquina`. O dado de treino está no DataFrame `df_treino` e o dado a ser avaliado (teste ou validação) é o `df_data_to_predict`. Tais DataFrames são compostos por um conjunto de colunas que são os atributos e uma coluna que é a classe alvo (o nome da coluna da classe está armazenado em `col_classe`).  Veja o exemplo abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chuvoso</th>\n",
       "      <th>ventos fortes</th>\n",
       "      <th>ensolarado</th>\n",
       "      <th>jogar volei?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sim</td>\n",
       "      <td>sim</td>\n",
       "      <td>não</td>\n",
       "      <td>não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>não</td>\n",
       "      <td>não</td>\n",
       "      <td>sim</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sim</td>\n",
       "      <td>não</td>\n",
       "      <td>não</td>\n",
       "      <td>sim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chuvoso ventos fortes ensolarado jogar volei?\n",
       "0     sim           sim        não          não\n",
       "1     não           não        sim          sim\n",
       "2     sim           não        não          sim"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_treino = pd.DataFrame([[\"sim\",\"sim\",\"não\",\"não\"],\n",
    "                           [\"não\",\"não\",\"sim\",\"sim\"],\n",
    "                         [\"sim\",\"não\",\"não\",\"sim\"]],\n",
    "                        columns=[\"chuvoso\",\"ventos fortes\",\"ensolarado\",\"jogar volei?\"])\n",
    "df_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exemplo o objetivo é verificar se é possível jogar uma partida de vôlei dependendo das situações climáticas. Neste contexto, `chuvoso`, `ventos fortes` e `ensolarado` são os atributos e `jogar volei?` é a classe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, você deve implementar o método `eval` da classe `ScikitLearnAprendizadoDeMaquina` para treinar e avaliar. Para isso, você deverá separar a coluna que se refere a classe e as colunas que se referem aos atributos. Logo após você deverá criar o modelo e executar o método predict() para obter a predições. No final, este método retorna uma instancia da classe `Resultado`.\n",
    "\n",
    "Execute o código abaixo para verificar o funcionamento deste método: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro f1: 0.5982142857142857 Acuracia: 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m tests MetodoTest.test_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - Criação dos folds:** O arquivo `resultado.py` possui a classe `Fold` que é responsável por armazenar o treino, teste e validação (quando existente). Essa classe possui os seguintes atributos: \n",
    "\n",
    "- `df_treino`: Dataframe com as instancias de treino. Cada instancia é uma linha e, suas colunas, são seus atributos e a sua classe\n",
    "- `df_data_to_predict`: Dataframe com as instancias de teste, representada da mesma forma que `df_treino`\n",
    "- `col_classe`: Coluna que representa a classe alvo nos DataFrames `df_treino` e `df_data_to_predict`\n",
    "- `arr_folds_validacao`: vetor com os folds de validação. Os folds de validação são também instancias da classe Fold. Tais instancias são construidas a partir do treino - você irá fazer isso nesta atividade. \n",
    "\n",
    "**Atividade 3(a):** Primeiramente, implemente o [método estático](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/#heranca) `gerar_k_folds`. A principio, ignore os parametros  `num_folds_validacao` e `num_repeticoes_validacao`. Este método divide em vários fold os dados `df_dados`. Cada fold deverá ser representado por uma instancia da classe Fold. Deve-se dividir o dataset em $k$ folds (parâmetro  `val_k`) e podem ser feitas $n$ repetições (parâmetro `num_repeticoes`). A escolha das instancias é feita sempre aleatória e, em cada repetição, todos os valores devem estar presentes  em apenas um teste. O treino ficaria com o restante dos valores. Veja abaixo um exemplo se dividirmos em três folds com duas repetições. Foi feito uma função para dividir em três folds e um exemplo em que foi gerado 2 repetições dele.  Para isso, usou-se a função [sample](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html) para embaralhar os dados e um seed fixo para que sempre embaralhar da mesma forma. Esse seed é essencial para que se garanta a repodutibilidade dos experimentos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resultado import Fold\n",
    "import pandas as pd\n",
    "def gera_tres_folds(df_dados, col_classe): \n",
    "    \n",
    "    fold_1 = Fold(df_treino=df_dados[3:]                            ,df_data_to_predict=df_dados[0:3],col_classe=col_classe)\n",
    "    fold_2 = Fold(df_treino=pd.concat([df_dados[0:3],df_dados[6:]]), df_data_to_predict=df_dados[3:6],col_classe=col_classe)\n",
    "    fold_3 = Fold(df_treino=df_dados[0:6]                       , df_data_to_predict=df_dados[6:9],col_classe=col_classe)\n",
    "    \n",
    "    return fold_1, fold_2, fold_3\n",
    "\n",
    "colunas = [\"atributo_1\",\"classe_alvo\"]\n",
    "col_classe = \"classe_alvo\"\n",
    "df_dados = pd.DataFrame([[0,\"S\"],[1,\"S\"],[2,\"N\"],\n",
    "                   [3,\"N\"],[4,\"N\"],[5,\"S\"],\n",
    "                   [6,\"S\"],[7,\"N\"],[8,\"S\"]], columns=colunas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atributo_1</th>\n",
       "      <th>classe_alvo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atributo_1 classe_alvo\n",
       "6           6           S\n",
       "7           7           N\n",
       "8           8           S"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#para ficar mais facil visualizar, comentamos o código abaixo e, assim, \n",
    "#. nao embaralhamos a primeira execução\n",
    "#. com isso, na primeira execucao os valores estarão ordenados de forma crescente \n",
    "#. pois foi esta a forma que foram inseridos\n",
    "#df_dados_rand = df_dados.sample(frac=1,random_state=2)\n",
    "fold_1,fold_2,fold_3 = gera_tres_folds(df_dados, col_classe)\n",
    "arr_folds = [fold_1,fold_2,fold_3]\n",
    "\n",
    "#veja o dado de treino ou a ser previsto de cada fold na primeira repetição \n",
    "#..(substitua o numero de fold o ou o atributo): \n",
    "fold_3.df_data_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeticao #0  Fold #0 instancias no treino: 6 teste: 3\n",
      "\tÍndices das instancias do treino: [3 4 5 6 7 8]\n",
      "\tÍndices das instancias a avaliar (teste ou validação): [0 1 2]\n",
      " \n",
      "Repeticao #0  Fold #1 instancias no treino: 6 teste: 3\n",
      "\tÍndices das instancias do treino: [0 1 2 6 7 8]\n",
      "\tÍndices das instancias a avaliar (teste ou validação): [3 4 5]\n",
      " \n",
      "Repeticao #0  Fold #2 instancias no treino: 6 teste: 3\n",
      "\tÍndices das instancias do treino: [0 1 2 3 4 5]\n",
      "\tÍndices das instancias a avaliar (teste ou validação): [6 7 8]\n",
      " \n",
      "Repeticao #1  Fold #0 instancias no treino: 6 teste: 3\n",
      "\tÍndices das instancias do treino: [2 3 0 5 7 8]\n",
      "\tÍndices das instancias a avaliar (teste ou validação): [4 1 6]\n",
      " \n",
      "Repeticao #1  Fold #1 instancias no treino: 6 teste: 3\n",
      "\tÍndices das instancias do treino: [4 1 6 5 7 8]\n",
      "\tÍndices das instancias a avaliar (teste ou validação): [2 3 0]\n",
      " \n",
      "Repeticao #1  Fold #2 instancias no treino: 6 teste: 3\n",
      "\tÍndices das instancias do treino: [4 1 6 2 3 0]\n",
      "\tÍndices das instancias a avaliar (teste ou validação): [5 7 8]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Na segunda execução, os folds devem ser diferentes ao embaralhar\n",
    "#por isso, usamos uma seed diferente\n",
    "#verifique que, mesmo executando várias vezes, como o seed é fixo,\n",
    "#o dataframe é sempre embaralhado da mesma forma. Isso ajuda a garantir a reprodutibilidade.\n",
    "df_dados_rand = df_dados.sample(frac=1,random_state=2)\n",
    "fold_1,fold_2,fold_3 = gera_tres_folds(df_dados_rand, col_classe)\n",
    "\n",
    "#adiciona mais os tres folds  na lista\n",
    "#veja em: https://www.geeksforgeeks.org/append-extend-python/\n",
    "arr_folds.extend([fold_1,fold_2,fold_3])\n",
    "\n",
    "#veja p resutado de todas as execucoes:\n",
    "num_repeticoes = 2\n",
    "val_k = 3\n",
    "for num_repeticao in range(num_repeticoes):\n",
    "    for num_fold in range(val_k):\n",
    "        i = val_k*num_repeticao+num_fold\n",
    "        df_treino  = arr_folds[i].df_treino\n",
    "        df_to_predict  = arr_folds[i].df_data_to_predict\n",
    "        qtd_treino = len(df_treino.index)\n",
    "        qtd_to_predict = len(df_to_predict.index)\n",
    "        print(f\"Repeticao #{num_repeticao}  Fold #{num_fold} instancias no treino: {qtd_treino} teste: {qtd_to_predict}\")\n",
    "        print(f\"\\tÍndices das instancias do treino: {df_treino.index.values}\")\n",
    "        print(f\"\\tÍndices das instancias a avaliar (teste ou validação): {df_to_predict.index.values}\")\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferentemente da função implementada acima, o método a ser implementado por vocês deverá ter uma quantidade qualquer de repetições (parâmetro `num_repeticoes`) e folds por repetição (parâmetro `val_k`). Ao criar o fold, também é necessário saber a coluna da classe, para isso, o parametro `col_classe` armazena seu valor. Implemente o método `gerar_k_folds`. Logo após, execute o seguinte teste automatizado: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m tests TestFold.test_gerar_k_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3(b):** Agora, você deverá inicialiar o atributo `arr_folds_validacao` com um vetor de folds de validação, por meio dos dados de treino, de acordo com o número de repetições e folds passados como parametro no construtor. Para isso, invoque o método `gerar_k_folds` no construtor - note que estes folds a serem criados não possuirão validação - possuirão apenas treino e dados a serem previstos (teste). \n",
    "\n",
    "Logo após, faça uma pequena modificação no `gerar_k_folds`: os parametros  `num_folds_validacao` e `num_repeticoes_validacao` indicam se o fold a ser criado possuirá validação. Ao instanciar o fold, esses parametros devem ser passados para o contrutor do Fold. Teste a execução a seguir: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python -m tests TestFold.test_arr_validacao"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
